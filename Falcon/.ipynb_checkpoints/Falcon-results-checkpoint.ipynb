{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niloufar/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import FalconTrainer as ft\n",
    "import peft\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,BitsAndBytesConfig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T20:24:27.577769426Z",
     "start_time": "2024-01-09T20:24:25.715274660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44874a266e9c4b8ab1a09cf03648e5e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'FloatProgress' object has no attribute 'style'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3081748/671669330.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mfalcon_trainer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLLMTrainer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"tiiuae/falcon-7b\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mval_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtest_dataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mft\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprepare_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfalcon_trainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mwith_tags\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/Project/radiology-surgical-report-correlation/Falcon/FalconTrainer.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, model_name, train_args)\u001B[0m\n\u001B[1;32m    158\u001B[0m             \u001B[0mbnb_4bit_use_double_quant\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m             bnb_4bit_compute_dtype=torch.float16,)\n\u001B[0;32m--> 160\u001B[0;31m         self.model=AutoModelForCausalLM.from_pretrained(\n\u001B[0m\u001B[1;32m    161\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m             \u001B[0mquantization_config\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn_config\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    559\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    560\u001B[0m                 \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel_class\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexist_ok\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 561\u001B[0;31m             return model_class.from_pretrained(\n\u001B[0m\u001B[1;32m    562\u001B[0m                 \u001B[0mpretrained_model_name_or_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mmodel_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mhub_kwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    563\u001B[0m             )\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3704\u001B[0m                 \u001B[0moffload_index\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3705\u001B[0m                 \u001B[0merror_msgs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3706\u001B[0;31m             \u001B[0;34m)\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_load_pretrained_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3707\u001B[0m                 \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3708\u001B[0m                 \u001B[0mstate_dict\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\u001B[0m in \u001B[0;36m_load_pretrained_model\u001B[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001B[0m\n\u001B[1;32m   4084\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4085\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresolved_archive_file\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4086\u001B[0;31m                 \u001B[0mresolved_archive_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlogging\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresolved_archive_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdesc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Loading checkpoint shards\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4087\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mshard_file\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mresolved_archive_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4088\u001B[0m                 \u001B[0;31m# Skip the load for shards that only contain disk-offloaded weights when using safetensors for the offload.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/logging.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    360\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    361\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_tqdm_active\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 362\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mtqdm_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    363\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    364\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mEmptyTqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/Project/MT-UNet/venv/lib/python3.10/site-packages/tqdm/notebook.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    238\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplayed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    239\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplay\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 240\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolour\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcolour\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    241\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    242\u001B[0m         \u001B[0;31m# Print initial bar state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/Project/MT-UNet/venv/lib/python3.10/site-packages/tqdm/notebook.py\u001B[0m in \u001B[0;36mcolour\u001B[0;34m(self, bar_color)\u001B[0m\n\u001B[1;32m    197\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcolour\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbar_color\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'container'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 199\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstyle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbar_color\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbar_color\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    200\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'FloatProgress' object has no attribute 'style'"
     ]
    }
   ],
   "source": [
    "falcon_trainer=ft.LLMTrainer(\"tiiuae/falcon-7b\")\n",
    "train_dataset,val_dataset,test_dataset=ft.prepare_data(falcon_trainer.tokenizer,with_tags=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T20:24:30.062958758Z",
     "start_time": "2024-01-09T20:24:28.558116092Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print (\"train size:\",train_dataset.data.shape)\n",
    "print (\"val size:\",val_dataset.data.shape)\n",
    "print (\"test size:\",test_dataset.data.shape)\n",
    "train_dataset.data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T20:10:12.254961053Z",
     "start_time": "2024-01-09T20:10:12.252746058Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "falcon_trainer= ft.LLMTrainer(\"tiiuae/falcon-7b\")\n",
    "train_dataset,val_dataset,test_dataset= ft.prepare_data(falcon_trainer.tokenizer,with_tags=False)\n",
    "# model_path=\"falcon-7b-trained-question-answer-note-tag\"\n",
    "# model_path=\"falcon-7b-trained-question-answer-note2\"\n",
    "model_path=\"saved-models/falcon-7b-trained-question-answer-note-integrity2\"\n",
    "config = peft.PeftConfig.from_pretrained(model_path)\n",
    "trained_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=falcon_trainer.bn_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = falcon_trainer.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "trained_model = peft.PeftModel.from_pretrained(\n",
    "    trained_model, model_path)\n",
    "falcon_trainer.peft_model=trained_model\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.255789614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction=[]\n",
    "for i in range(len(test_dataset)):\n",
    "    q=test_dataset[i]['q']\n",
    "    a=test_dataset[i]['a']\n",
    "    question=test_dataset.data['question'][i]\n",
    "    encoding = tokenizer(\"<question>:\" + question + \"<answer>:\" , return_tensors=\"pt\").to(falcon_trainer.device)\n",
    "    output = falcon_trainer.peft_model.generate(input_ids=encoding.input_ids,attention_mask=encoding.attention_mask ,max_new_tokens=50 )\n",
    "    output=tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\">> generated:\", output[output.find(\"<answer>:\"):].replace(\"<answer>:\",\"\"))\n",
    "    print(\">> answer:\", a)\n",
    "    print(\"--------{:<}-----------\".format(test_dataset.data.iloc[i]['report_type']))\n",
    "    prediction.append(output[output.find(\"<answer>:\"):].replace(\"<answer>:\",\"\"))\n",
    "    \n",
    "    # print(\">> generated:\", output[output.find(\"<answer>:\"):].replace(\"<answer>:\",\"\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.258126438Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.260902871Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.263855176Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.266779367Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_pd.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.269265262Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result_pd=pd.DataFrame({'question':test_dataset.data['question'],'answer':test_dataset.data['answer'],'prediction':prediction,\"report_type\":test_dataset.data.report_type})\n",
    "result_pd.to_excel('../results/result-integrity2-max-new-tokens-50.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.311412240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_pd.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.311684403Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_pd.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.311829717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset.data['report_type']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.311953520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T20:10:12.312093494Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
